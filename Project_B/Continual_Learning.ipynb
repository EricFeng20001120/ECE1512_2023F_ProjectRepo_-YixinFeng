{"cells":[{"cell_type":"markdown","source":["### Reference\n","https://github.com/VICO-UoE/DatasetCondensation"],"metadata":{"id":"skBIfyB5F1Ps"}},{"cell_type":"markdown","source":["# Continual Learning"],"metadata":{"id":"3LghZjw3F5KT"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21895,"status":"ok","timestamp":1700602774824,"user":{"displayName":"Eric Feng","userId":"12633795715277578355"},"user_tz":300},"id":"R5k9BOgm3S91","outputId":"4be10c28-aafc-4ef8-bfd0-82261d5e1b3d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/MyDrive/ECE1513/Project_B_Supp\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/ECE1513/Project_B_Supp/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A-l43hDQ9ded"},"outputs":[],"source":["import os\n","import numpy as np\n","import torch\n","import argparse\n","from utils import get_dataset, get_network, get_eval_pool, evaluate_synset, ParamDiffAug, TensorDataset\n","import copy\n","import gc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YqrRqJLuoDNX"},"outputs":[],"source":["def continual_learning():\n","  channel, im_size, num_classes, class_names, mean, std, dst_train, dst_test, testloader = get_dataset(args.dataset, args.data_path)\n","  ''' all training data '''\n","  images_all = []\n","  labels_all = []\n","  indices_class = [[] for c in range(num_classes)]\n","\n","  images_all = [torch.unsqueeze(dst_train[i][0], dim=0) for i in range(len(dst_train))]\n","  labels_all = [dst_train[i][1] for i in range(len(dst_train))]\n","  for i, lab in enumerate(labels_all):\n","      indices_class[lab].append(i)\n","  images_all = torch.cat(images_all, dim=0).to(args.device)\n","  labels_all = torch.tensor(labels_all, dtype=torch.long, device=args.device)\n","\n","  def get_images(c, n):  # get random n images from class c\n","      idx_shuffle = np.random.permutation(indices_class[c])[:n]\n","      return images_all[idx_shuffle]\n","\n","  print()\n","  print('==================================================================================')\n","  print('method: ', args.method)\n","  results = np.zeros((args.steps, 5*args.num_eval))\n","\n","  for seed_cl in range(1):\n","    num_classes_step = num_classes // args.steps\n","    np.random.seed(seed_cl)\n","    class_order = np.random.permutation(num_classes).tolist()\n","    print('=========================================')\n","    print('seed: ', seed_cl)\n","    print('class_order: ', class_order)\n","    print('augmentation strategy: \\n', args.dsa_strategy)\n","    print('augmentation parameters: \\n', args.dsa_param.__dict__)\n","\n","    if args.method == 'random':\n","        images_train_all = []\n","        labels_train_all = []\n","        for step in range(args.steps):\n","            classes_current = class_order[step * num_classes_step: (step + 1) * num_classes_step]\n","            images_train_all += [torch.cat([get_images(c, args.ipc) for c in classes_current], dim=0)]\n","            labels_train_all += [torch.tensor([c for c in classes_current for i in range(args.ipc)], dtype=torch.long, device=args.device)]\n","\n","    if args.dataset == 'MNIST':\n","      image_syn = torch.load('image_syn_mnist.pt',map_location=torch.device('cpu')).to(args.device)\n","      label_syn = torch.load('label_syn_mnist.pt',map_location=torch.device('cpu')).to(args.device)\n","\n","    elif args.dataset == 'MHIST':\n","      image_syn = torch.load('image_syn.pt',map_location=torch.device('cpu')).to(args.device)\n","      label_syn = torch.load('label_syn.pt',map_location=torch.device('cpu')).to(args.device)\n","\n","\n","    for step in range(args.steps):\n","        print('\\n-----------------------------\\nmethod %s seed %d step %d ' % (args.method, seed_cl, step))\n","\n","        classes_seen = class_order[: (step+1)*num_classes_step]\n","        print('classes_seen: ', classes_seen)\n","\n","\n","        ''' train real data '''\n","        images_train = torch.cat(images_train_all[:step+1], dim=0).to(args.device)\n","        labels_train = torch.cat(labels_train_all[:step+1], dim=0).to(args.device)\n","        print('train data size: ', images_train.shape)\n","\n","        '''Train synthetic data'''\n","        mask = torch.isin(label_syn, torch.tensor(classes_seen, device=args.device))\n","        images_train_syn = image_syn[mask]\n","        labels_train_syn = label_syn[mask]\n","\n","        ''' test data '''\n","        images_test = []\n","        labels_test = []\n","        for i in range(len(dst_test)):\n","            lab = int(dst_test[i][1])\n","            if lab in classes_seen:\n","                images_test.append(torch.unsqueeze(dst_test[i][0], dim=0))\n","                labels_test.append(dst_test[i][1])\n","\n","        images_test = torch.cat(images_test, dim=0).to(args.device)\n","        labels_test = torch.tensor(labels_test, dtype=torch.long, device=args.device)\n","        dst_test_current = TensorDataset(images_test, labels_test)\n","        testloader = torch.utils.data.DataLoader(dst_test_current, batch_size=256, shuffle=False, num_workers=0)\n","\n","        print('test set size: ', images_test.shape)\n","\n","\n","        '''Train model on synthetic dataset'''\n","        accs = []\n","        for ep_eval in range(args.num_eval):\n","            net_eval = get_network(args.model, channel, num_classes, im_size)\n","            net_eval = net_eval.to(args.device)\n","            img_syn_eval = copy.deepcopy(images_train_syn.detach())\n","            lab_syn_eval = copy.deepcopy(labels_train_syn.detach())\n","\n","            _, acc_train, acc_test = evaluate_synset(ep_eval, net_eval, img_syn_eval, lab_syn_eval, testloader, args)\n","            del net_eval, img_syn_eval, lab_syn_eval\n","            gc.collect()  # to reduce memory cost\n","            accs.append(acc_test)\n","            results[step, seed_cl*args.num_eval + ep_eval] = acc_test\n","        print('With synthetic dataset: Evaluate %d random %s, mean = %.4f std = %.4f' % (len(accs), args.model, np.mean(accs), np.std(accs)))\n","\n","\n","        ''' train model on the newest memory '''\n","        accs = []\n","        for ep_eval in range(args.num_eval):\n","            net_eval = get_network(args.model, channel, num_classes, im_size)\n","            net_eval = net_eval.to(args.device)\n","            img_syn_eval = copy.deepcopy(images_train.detach())\n","            lab_syn_eval = copy.deepcopy(labels_train.detach())\n","\n","            _, acc_train, acc_test = evaluate_synset(ep_eval, net_eval, img_syn_eval, lab_syn_eval, testloader, args)\n","            del net_eval, img_syn_eval, lab_syn_eval\n","            gc.collect()  # to reduce memory cost\n","            accs.append(acc_test)\n","            results[step, seed_cl*args.num_eval + ep_eval] = acc_test\n","        print('With real dataset: Evaluate %d random %s, mean = %.4f std = %.4f' % (len(accs), args.model, np.mean(accs), np.std(accs)))\n","\n","\n","  results_str = ''\n","  for step in range(args.steps):\n","      results_str += '& %.1f$\\pm$%.1f  ' % (np.mean(results[step]) * 100, np.std(results[step]) * 100)\n","  print('\\n\\n')\n","  print('%d step learning %s perforamnce:'%(args.steps, args.method))\n","  print(results_str)\n","  print('Done')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1314628,"status":"error","timestamp":1700604608074,"user":{"displayName":"Eric Feng","userId":"12633795715277578355"},"user_tz":300},"id":"W0_jcyIlzbv4","outputId":"ad7bab59-5061-4c04-ebc9-714ea6e89495"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","==================================================================================\n","method:  random\n","=========================================\n","seed:  0\n","class_order:  [2, 8, 4, 9, 1, 6, 7, 3, 0, 5]\n","augmentation strategy: \n"," color_crop_cutout_flip_scale_rotate\n","augmentation parameters: \n"," {'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5}\n","\n","-----------------------------\n","method random seed 0 step 0 \n","classes_seen:  [2, 8, 4]\n","train data size:  torch.Size([30, 1, 28, 28])\n","test set size:  torch.Size([2988, 1, 28, 28])\n","[2023-11-21 22:41:17] Evaluate_00: epoch = 0200 train time = 57 s train loss = 0.000449 train acc = 1.0000, test acc = 0.9391\n","[2023-11-21 22:42:25] Evaluate_01: epoch = 0200 train time = 54 s train loss = 0.000401 train acc = 1.0000, test acc = 0.9357\n","[2023-11-21 22:43:34] Evaluate_02: epoch = 0200 train time = 56 s train loss = 0.000536 train acc = 1.0000, test acc = 0.9388\n","With synthetic dataset: Evaluate 3 random ConvNet, mean = 0.9379 std = 0.0015\n","[2023-11-21 22:44:46] Evaluate_00: epoch = 0200 train time = 57 s train loss = 0.000575 train acc = 1.0000, test acc = 0.9518\n","[2023-11-21 22:45:54] Evaluate_01: epoch = 0200 train time = 55 s train loss = 0.000531 train acc = 1.0000, test acc = 0.9515\n","[2023-11-21 22:47:05] Evaluate_02: epoch = 0200 train time = 57 s train loss = 0.000560 train acc = 1.0000, test acc = 0.9521\n","With real dataset: Evaluate 3 random ConvNet, mean = 0.9518 std = 0.0003\n","\n","-----------------------------\n","method random seed 0 step 1 \n","classes_seen:  [2, 8, 4, 9, 1, 6]\n","train data size:  torch.Size([60, 1, 28, 28])\n","test set size:  torch.Size([6090, 1, 28, 28])\n","[2023-11-21 22:49:36] Evaluate_00: epoch = 0200 train time = 120 s train loss = 0.002412 train acc = 1.0000, test acc = 0.9335\n","[2023-11-21 22:51:59] Evaluate_01: epoch = 0200 train time = 115 s train loss = 0.002367 train acc = 1.0000, test acc = 0.9314\n","[2023-11-21 22:54:27] Evaluate_02: epoch = 0200 train time = 122 s train loss = 0.002397 train acc = 1.0000, test acc = 0.9389\n","With synthetic dataset: Evaluate 3 random ConvNet, mean = 0.9346 std = 0.0032\n","[2023-11-21 22:56:47] Evaluate_00: epoch = 0200 train time = 110 s train loss = 0.002012 train acc = 1.0000, test acc = 0.9294\n","[2023-11-21 22:59:13] Evaluate_01: epoch = 0200 train time = 119 s train loss = 0.002412 train acc = 1.0000, test acc = 0.9228\n","[2023-11-21 23:01:37] Evaluate_02: epoch = 0200 train time = 116 s train loss = 0.002215 train acc = 1.0000, test acc = 0.9186\n","With real dataset: Evaluate 3 random ConvNet, mean = 0.9236 std = 0.0045\n","\n","-----------------------------\n","method random seed 0 step 2 \n","classes_seen:  [2, 8, 4, 9, 1, 6, 7, 3, 0]\n","train data size:  torch.Size([90, 1, 28, 28])\n","test set size:  torch.Size([9108, 1, 28, 28])\n","[2023-11-21 23:05:38] Evaluate_00: epoch = 0200 train time = 192 s train loss = 0.005098 train acc = 1.0000, test acc = 0.9237\n","[2023-11-21 23:09:34] Evaluate_01: epoch = 0200 train time = 191 s train loss = 0.005261 train acc = 1.0000, test acc = 0.9234\n","[2023-11-21 23:13:28] Evaluate_02: epoch = 0200 train time = 190 s train loss = 0.005026 train acc = 1.0000, test acc = 0.9269\n","With synthetic dataset: Evaluate 3 random ConvNet, mean = 0.9246 std = 0.0016\n","[2023-11-21 23:17:20] Evaluate_00: epoch = 0200 train time = 192 s train loss = 0.004593 train acc = 1.0000, test acc = 0.9047\n","[2023-11-21 23:21:17] Evaluate_01: epoch = 0200 train time = 197 s train loss = 0.005332 train acc = 1.0000, test acc = 0.8982\n","[2023-11-21 23:25:16] Evaluate_02: epoch = 0200 train time = 199 s train loss = 0.004997 train acc = 1.0000, test acc = 0.8971\n","With real dataset: Evaluate 3 random ConvNet, mean = 0.9000 std = 0.0033\n","\n","\n","\n","3 step learning random perforamnce:\n","& 19.0$\\pm$38.1  & 18.5$\\pm$36.9  & 18.0$\\pm$36.0  \n","Done\n"]}],"source":["args = type('', (), {})()\n","args.method = 'random'\n","args.dataset = 'MNIST'\n","args.model = 'ConvNet'\n","args.ipc=10\n","args.steps = 3\n","args.num_eval = 3 # evaluation number\n","args.epoch_eval_train = 200 # epochs to train a model with synthetic data\n","args.lr_net = 0.01\n","args.batch_train = 256\n","args.data_path = './data'\n","\n","args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","args.dsa_param = ParamDiffAug()\n","args.dsa = False # augment images for all methods\n","args.dsa_strategy = 'color_crop_cutout_flip_scale_rotate' # for CIFAR10/100\n","args.dc_aug_param = None\n","\n","continual_learning()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1101965,"status":"ok","timestamp":1700606221584,"user":{"displayName":"Eric Feng","userId":"12633795715277578355"},"user_tz":300},"id":"f8W5gGK2rcd7","outputId":"6dcd3c22-d630-456e-d22f-325cf90d08b7"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","==================================================================================\n","method:  random\n","=========================================\n","seed:  0\n","class_order:  [1, 0]\n","augmentation strategy: \n"," color_crop_cutout_flip_scale_rotate\n","augmentation parameters: \n"," {'aug_mode': 'S', 'prob_flip': 0.5, 'ratio_scale': 1.2, 'ratio_rotate': 15.0, 'ratio_crop_pad': 0.125, 'ratio_cutout': 0.5, 'brightness': 1.0, 'saturation': 2.0, 'contrast': 0.5}\n","\n","-----------------------------\n","method random seed 0 step 0 \n","classes_seen:  [1]\n","train data size:  torch.Size([10, 3, 32, 32])\n","test set size:  torch.Size([360, 3, 32, 32])\n","[2023-11-21 22:30:41] Evaluate_00: epoch = 0200 train time = 18 s train loss = 0.000000 train acc = 1.0000, test acc = 1.0000\n","[2023-11-21 22:31:11] Evaluate_01: epoch = 0200 train time = 28 s train loss = 0.000000 train acc = 1.0000, test acc = 1.0000\n","[2023-11-21 22:31:32] Evaluate_02: epoch = 0200 train time = 19 s train loss = 0.000000 train acc = 1.0000, test acc = 1.0000\n","With synthetic dataset: Evaluate 3 random ConvNet, mean = 1.0000 std = 0.0000\n","[2023-11-21 22:31:53] Evaluate_00: epoch = 0200 train time = 19 s train loss = 0.000000 train acc = 1.0000, test acc = 1.0000\n","[2023-11-21 22:32:14] Evaluate_01: epoch = 0200 train time = 19 s train loss = 0.000000 train acc = 1.0000, test acc = 1.0000\n","[2023-11-21 22:32:37] Evaluate_02: epoch = 0200 train time = 20 s train loss = 0.000000 train acc = 1.0000, test acc = 1.0000\n","With real dataset: Evaluate 3 random ConvNet, mean = 1.0000 std = 0.0000\n","\n","-----------------------------\n","method random seed 0 step 1 \n","classes_seen:  [1, 0]\n","train data size:  torch.Size([20, 3, 32, 32])\n","test set size:  torch.Size([977, 3, 32, 32])\n","[2023-11-21 22:33:32] Evaluate_00: epoch = 0200 train time = 38 s train loss = 0.000337 train acc = 1.0000, test acc = 0.5312\n","[2023-11-21 22:34:12] Evaluate_01: epoch = 0200 train time = 36 s train loss = 0.000421 train acc = 1.0000, test acc = 0.5302\n","[2023-11-21 22:34:55] Evaluate_02: epoch = 0200 train time = 36 s train loss = 0.000359 train acc = 1.0000, test acc = 0.5292\n","With synthetic dataset: Evaluate 3 random ConvNet, mean = 0.5302 std = 0.0008\n","[2023-11-21 22:35:39] Evaluate_00: epoch = 0200 train time = 39 s train loss = 0.000345 train acc = 1.0000, test acc = 0.5097\n","[2023-11-21 22:36:19] Evaluate_01: epoch = 0200 train time = 36 s train loss = 0.000321 train acc = 1.0000, test acc = 0.5292\n","[2023-11-21 22:37:01] Evaluate_02: epoch = 0200 train time = 36 s train loss = 0.000361 train acc = 1.0000, test acc = 0.4995\n","With real dataset: Evaluate 3 random ConvNet, mean = 0.5128 std = 0.0123\n","\n","\n","\n","2 step learning random perforamnce:\n","& 20.0$\\pm$40.0  & 10.3$\\pm$20.5  \n","Done\n"]}],"source":["args = type('', (), {})()\n","args.method = 'random'\n","args.dataset = 'MHIST'\n","args.model = 'ConvNet'\n","args.ipc=10\n","args.steps = 2\n","args.num_eval = 3 # evaluation number\n","args.epoch_eval_train = 200 # epochs to train a model with synthetic data\n","args.lr_net = 0.01\n","args.batch_train = 128\n","args.data_path = './data'\n","\n","args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","args.dsa_param = ParamDiffAug()\n","args.dsa = False # augment images for all methods\n","args.dsa_strategy = 'color_crop_cutout_flip_scale_rotate' # for CIFAR10/100\n","args.dc_aug_param = None\n","continual_learning()"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOtZVGRrx9J391kwwOHx2MZ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}